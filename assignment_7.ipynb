{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MKDU9v3XjbhZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('letter-recognition.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into input features and target labels\n",
        "X = dataset.drop(['letter'], axis=1).values\n",
        "y = pd.get_dummies(dataset['letter']).values\n",
        "\n",
        "# Scale the input features to be between 0 and 1\n",
        "X = X / 255.0\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "fVhtZzLTlIYs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=16, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ofe7mfQjmOoq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leD6L7wDmcE1",
        "outputId": "d21b9f8b-9683-4eba-89dc-e4552d3a9d72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 2s 2ms/step - loss: 2.8609 - accuracy: 0.1497 - val_loss: 2.2386 - val_accuracy: 0.3038\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 2.1137 - accuracy: 0.3455 - val_loss: 2.0056 - val_accuracy: 0.4202\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.9007 - accuracy: 0.4260 - val_loss: 1.8181 - val_accuracy: 0.4288\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 1.7565 - accuracy: 0.4686 - val_loss: 1.7232 - val_accuracy: 0.4705\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 1.6823 - accuracy: 0.4958 - val_loss: 1.6417 - val_accuracy: 0.4985\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 1.6176 - accuracy: 0.5125 - val_loss: 1.5940 - val_accuracy: 0.5170\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.5675 - accuracy: 0.5279 - val_loss: 1.5120 - val_accuracy: 0.5412\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.5245 - accuracy: 0.5429 - val_loss: 1.4833 - val_accuracy: 0.5502\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.4885 - accuracy: 0.5541 - val_loss: 1.4504 - val_accuracy: 0.5650\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.4560 - accuracy: 0.5649 - val_loss: 1.4122 - val_accuracy: 0.5745\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.4237 - accuracy: 0.5742 - val_loss: 1.4267 - val_accuracy: 0.5702\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.3900 - accuracy: 0.5894 - val_loss: 1.3590 - val_accuracy: 0.5947\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.3600 - accuracy: 0.5969 - val_loss: 1.3426 - val_accuracy: 0.5890\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.3212 - accuracy: 0.6079 - val_loss: 1.2892 - val_accuracy: 0.6087\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.2841 - accuracy: 0.6173 - val_loss: 1.2570 - val_accuracy: 0.6273\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.2462 - accuracy: 0.6269 - val_loss: 1.2013 - val_accuracy: 0.6350\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.2100 - accuracy: 0.6414 - val_loss: 1.1699 - val_accuracy: 0.6570\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.1785 - accuracy: 0.6479 - val_loss: 1.1254 - val_accuracy: 0.6672\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.1450 - accuracy: 0.6638 - val_loss: 1.1071 - val_accuracy: 0.6817\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 1.1114 - accuracy: 0.6660 - val_loss: 1.0592 - val_accuracy: 0.6892\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 1.0801 - accuracy: 0.6744 - val_loss: 1.0307 - val_accuracy: 0.6973\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.0421 - accuracy: 0.6862 - val_loss: 0.9923 - val_accuracy: 0.7005\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.0082 - accuracy: 0.6967 - val_loss: 0.9751 - val_accuracy: 0.7045\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.9773 - accuracy: 0.7031 - val_loss: 0.9548 - val_accuracy: 0.7172\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.9475 - accuracy: 0.7119 - val_loss: 0.9107 - val_accuracy: 0.7278\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.9189 - accuracy: 0.7219 - val_loss: 0.9140 - val_accuracy: 0.7225\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8937 - accuracy: 0.7272 - val_loss: 0.8627 - val_accuracy: 0.7440\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8711 - accuracy: 0.7334 - val_loss: 0.8610 - val_accuracy: 0.7390\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8519 - accuracy: 0.7377 - val_loss: 0.8240 - val_accuracy: 0.7508\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8306 - accuracy: 0.7437 - val_loss: 0.8090 - val_accuracy: 0.7505\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8144 - accuracy: 0.7462 - val_loss: 0.8018 - val_accuracy: 0.7545\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.8011 - accuracy: 0.7526 - val_loss: 0.7640 - val_accuracy: 0.7675\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.7835 - accuracy: 0.7556 - val_loss: 0.7489 - val_accuracy: 0.7740\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.7667 - accuracy: 0.7617 - val_loss: 0.7396 - val_accuracy: 0.7805\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.7559 - accuracy: 0.7661 - val_loss: 0.7608 - val_accuracy: 0.7602\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.7712 - val_loss: 0.7417 - val_accuracy: 0.7617\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.7285 - accuracy: 0.7708 - val_loss: 0.7340 - val_accuracy: 0.7775\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.7213 - accuracy: 0.7722 - val_loss: 0.7194 - val_accuracy: 0.7790\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.7069 - accuracy: 0.7784 - val_loss: 0.6767 - val_accuracy: 0.7905\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.7854 - val_loss: 0.7027 - val_accuracy: 0.7807\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.7831 - val_loss: 0.6883 - val_accuracy: 0.7845\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.7876 - val_loss: 0.6784 - val_accuracy: 0.7897\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6618 - accuracy: 0.7918 - val_loss: 0.6430 - val_accuracy: 0.8083\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6551 - accuracy: 0.7944 - val_loss: 0.6324 - val_accuracy: 0.8083\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6438 - accuracy: 0.7968 - val_loss: 0.6330 - val_accuracy: 0.8058\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6322 - accuracy: 0.7996 - val_loss: 0.6507 - val_accuracy: 0.7922\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6260 - accuracy: 0.8033 - val_loss: 0.6473 - val_accuracy: 0.7918\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6200 - accuracy: 0.8039 - val_loss: 0.6202 - val_accuracy: 0.8050\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6128 - accuracy: 0.8064 - val_loss: 0.6278 - val_accuracy: 0.8018\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6028 - accuracy: 0.8092 - val_loss: 0.6104 - val_accuracy: 0.8065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGkV9fNQm5W_",
        "outputId": "4a4e1865-137b-490c-ac81-558c01a1ef60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 0s - loss: 0.6104 - accuracy: 0.8065 - 98ms/epoch - 784us/step\n",
            "Test accuracy: 0.8065000176429749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTCi3gc_nS51",
        "outputId": "a7eab72e-5c2b-460e-ddce-eafa30377e60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 773us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print('Predicted:', predictions[i], 'Actual:', y_test[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BPMHONYFXUP",
        "outputId": "a1463e38-5824-4139-fe8e-677820f5bac6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [7.8052626e-06 1.1120584e-04 1.8278080e-05 2.2607310e-04 1.6433556e-02\n",
            " 7.9030964e-05 1.1349996e-03 2.9607135e-04 1.8265119e-02 1.0613563e-03\n",
            " 8.7152213e-05 1.7056962e-02 5.0622295e-10 1.7576852e-09 4.0357427e-06\n",
            " 9.3802321e-08 1.5329994e-02 1.7628980e-05 5.3023804e-02 3.4595716e-03\n",
            " 5.0040553e-06 5.6811542e-09 1.1183811e-23 4.6230391e-01 1.7074895e-05\n",
            " 4.1106126e-01] Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "Predicted: [7.2939955e-03 2.0068290e-02 1.9454207e-02 1.8468298e-02 7.2176136e-02\n",
            " 5.0045084e-02 5.2838236e-02 1.7904131e-01 7.3606195e-03 1.3564295e-02\n",
            " 1.8772608e-02 1.5476367e-01 6.2933378e-03 5.2074059e-03 4.5994855e-03\n",
            " 8.1249764e-03 2.0311365e-02 3.1015176e-02 1.3322246e-02 1.5710478e-01\n",
            " 1.6735418e-02 2.0459628e-02 1.8977292e-06 6.7184582e-02 3.2902405e-02\n",
            " 2.8904262e-03] Actual: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [9.9811685e-01 7.6833735e-14 2.5421123e-13 2.2370113e-08 7.1972717e-13\n",
            " 8.2226740e-14 2.1347941e-09 1.6157621e-07 1.4979521e-06 1.3260171e-03\n",
            " 1.6767589e-07 5.4048991e-04 2.0189965e-10 2.9781821e-09 1.6662977e-08\n",
            " 4.2308110e-15 9.1794300e-06 1.4505984e-08 2.3931020e-06 3.6635025e-11\n",
            " 2.3317195e-09 2.6180668e-15 1.1036981e-23 3.0978463e-06 5.3324410e-14\n",
            " 6.0711125e-09] Actual: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [1.8365609e-10 1.0085254e-03 1.0083417e-03 2.0341922e-05 8.4054810e-01\n",
            " 1.0029972e-04 1.0173969e-01 9.4460802e-06 2.3047945e-03 1.4248267e-05\n",
            " 1.0597823e-06 4.2151113e-04 1.8752115e-13 2.0766769e-12 1.4093697e-04\n",
            " 1.6357661e-06 2.2582777e-03 1.4894992e-05 4.7325108e-02 2.6391580e-04\n",
            " 8.1250749e-07 3.1314332e-10 2.2728797e-27 2.2580160e-04 7.5971982e-08\n",
            " 2.5922537e-03] Actual: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [1.8500447e-07 4.1944923e-09 8.3660037e-05 6.6362622e-07 5.3034529e-07\n",
            " 2.5692211e-09 2.3457525e-02 5.2063360e-06 4.0452364e-06 3.8140587e-07\n",
            " 7.0540668e-10 7.0978946e-05 1.2066101e-11 4.1784878e-10 2.7762614e-03\n",
            " 1.1425241e-07 9.7317147e-01 7.4406109e-10 3.9903389e-04 3.1838629e-06\n",
            " 2.3261218e-05 4.4664723e-08 8.3653732e-20 2.7814674e-06 5.9070254e-07\n",
            " 1.1640805e-08] Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [4.0351037e-20 1.3357672e-13 3.5112032e-03 3.2924830e-16 9.8736966e-01\n",
            " 3.2298147e-10 8.5027413e-03 7.2637974e-14 1.7101582e-05 1.3899980e-10\n",
            " 1.0807248e-09 5.6468147e-05 1.9881701e-28 9.2718189e-27 1.9206151e-10\n",
            " 5.4864696e-16 1.0338084e-06 1.3777824e-17 5.9446225e-05 2.2093900e-08\n",
            " 4.9881098e-12 7.1582410e-17 0.0000000e+00 1.6777404e-08 4.5447110e-10\n",
            " 4.8248318e-04] Actual: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [1.9230622e-07 3.4477551e-08 1.6466494e-05 1.4151660e-03 2.8359935e-07\n",
            " 2.1560977e-08 1.3207854e-02 1.0130658e-03 1.4171268e-05 2.3446335e-04\n",
            " 1.4055755e-09 4.2816468e-05 8.1996815e-10 2.9184179e-07 9.5578158e-01\n",
            " 6.9279504e-06 2.7304897e-02 3.5831056e-06 8.6442253e-04 9.5619207e-08\n",
            " 9.3684102e-05 5.2514735e-09 1.3846491e-18 1.7923773e-08 5.0783611e-10\n",
            " 1.0563871e-11] Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [3.3188440e-04 3.9679744e-08 3.5250105e-05 1.5212679e-08 1.8537000e-06\n",
            " 1.6838075e-07 4.6224566e-03 6.6680500e-06 1.3711980e-05 8.9469680e-08\n",
            " 4.2125023e-08 4.8664402e-05 1.3184719e-09 4.7025757e-09 1.0547339e-04\n",
            " 1.0086344e-06 9.9422997e-01 3.6917891e-10 2.9265715e-04 3.8076087e-05\n",
            " 8.1558601e-06 1.8522644e-05 5.4439373e-14 3.1912641e-05 2.1282754e-04\n",
            " 5.0457487e-07] Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [4.3353525e-06 1.4304710e-10 1.0188143e-01 4.7098324e-06 1.2741513e-04\n",
            " 8.0700389e-09 7.4089611e-01 3.9295740e-03 2.7280394e-06 1.9144494e-05\n",
            " 2.3285605e-02 6.9801725e-02 5.5756548e-08 2.9602407e-07 8.3106980e-03\n",
            " 2.4698945e-09 4.7811445e-02 2.8005313e-06 7.1662304e-04 2.8263805e-06\n",
            " 2.6314696e-03 3.7526198e-07 4.8545983e-16 5.7040743e-04 4.9470824e-08\n",
            " 1.0598204e-07] Actual: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predicted: [1.5493411e-06 1.6606412e-08 7.0414154e-07 5.8175404e-02 3.0464696e-07\n",
            " 4.1350841e-08 3.7379385e-04 7.3742494e-02 1.3578490e-05 2.8160857e-03\n",
            " 7.6100392e-08 4.7432972e-04 2.0450376e-07 9.1475413e-05 8.5901576e-01\n",
            " 4.0575692e-06 3.0715177e-03 1.5874335e-03 1.0403432e-04 3.7256066e-07\n",
            " 5.2650459e-04 4.6844288e-09 1.4305246e-16 1.5092630e-07 1.5618238e-11\n",
            " 6.6017158e-14] Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    }
  ]
}